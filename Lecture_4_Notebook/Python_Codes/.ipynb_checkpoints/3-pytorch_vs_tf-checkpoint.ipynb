{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"https://www.imaginarycloud.com/blog/content/images/2021/04/pytorchvs_cover.png\" \n",
    "   width=\"500\" style=\"margin: 5px auto; display: block; position: relative; left: -20px;\" />\n",
    "</div>\n",
    "\n",
    "<!--NAVIGATION-->\n",
    "# [Python Primer](1-python_primer.ipynb) | [PyTorch Primer](2-pytorch.ipynb) | [TensorFlow Primer](3-tf.ipynb)  | PyT vs TF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submodule -1.4 : A Primer on PyTorch and Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "#### 1. [Gradient: PyTorch vs TensorFlow](#Gradient:-PyTorch-vs-TensorFlow)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient: PyTorch vs TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 20.08553692,  54.59815003, 403.42879349])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# TensorFlow 2.x: Computing 1st and 2nd Derivatives (Autodiff)\n",
    "# ============================================================\n",
    "#\n",
    "# Goal:\n",
    "#   Compute the second derivative d^2/dx^2 of y = exp(x)\n",
    "#   for a vector input x = [3, 4, 6]\n",
    "#\n",
    "# Key TF2 concept:\n",
    "#   TensorFlow computes gradients inside a `tf.GradientTape()` context.\n",
    "#   - You \"record\" operations on a tape\n",
    "#   - Then ask the tape for gradients\n",
    "#\n",
    "# Compared to PyTorch:\n",
    "#   - PyTorch: set requires_grad=True on tensors and call backward()\n",
    "#   - TF2: use GradientTape and explicitly watch tensors (unless they are Variables)\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "tf.config.run_functions_eagerly(False)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Create input data (NumPy) and convert to TensorFlow tensor\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# NumPy array (no gradient tracking in NumPy)\n",
    "x = np.array([3.0, 4.0, 6.0])\n",
    "\n",
    "# Convert NumPy array to a TensorFlow Tensor\n",
    "# NOTE:\n",
    "# - tf.Tensor is NOT automatically watched by GradientTape\n",
    "# - If you want gradients for a tf.Tensor, you must call tape.watch(...)\n",
    "x_tensor = tf.convert_to_tensor(x)\n",
    "#x_tensor = tf.Variable(x_tensor)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Function to compute second derivative using nested tapes\n",
    "# ------------------------------------------------------------\n",
    "#@tf.function(jit_compile=True)\n",
    "def fun_g2(x_tensor):\n",
    "    \"\"\"\n",
    "    Computes d2y/dx2 for y = exp(x) using nested GradientTapes.\n",
    "\n",
    "    Why nested tapes?\n",
    "    - Inner tape (g) computes first derivative dy/dx\n",
    "    - Outer tape (f) differentiates dy/dx again to compute d2y/dx2\n",
    "\n",
    "    persistent=True:\n",
    "    - Allows calling .gradient(...) multiple times on the same tape.\n",
    "    - Without persistent=True, a tape can be used only once.\n",
    "    \"\"\"\n",
    "\n",
    "    # Outer tape: records operations needed to compute gradient of dy_dx\n",
    "    with tf.GradientTape(persistent=True) as f:\n",
    "\n",
    "        # Because x_tensor is a tf.Tensor (not tf.Variable),\n",
    "        # we must explicitly tell the tape to track it.\n",
    "        f.watch(x_tensor)\n",
    "\n",
    "        # Inner tape: records operations needed to compute gradient of y\n",
    "        with tf.GradientTape(persistent=True) as g:\n",
    "\n",
    "            # Again, explicitly watch the tensor\n",
    "            g.watch(x_tensor)\n",
    "\n",
    "            # Forward computation: y = exp(x)\n",
    "            y = tf.exp(x_tensor)\n",
    "\n",
    "        # First derivative: dy/dx\n",
    "        # For y = exp(x), dy/dx = exp(x)\n",
    "        dy_dx = g.gradient(y, x_tensor)\n",
    "\n",
    "    # Second derivative: d/dx(dy/dx)\n",
    "    # Since dy/dx = exp(x), d2y/dx2 = exp(x) as well\n",
    "    d2y_dx2 = f.gradient(dy_dx, x_tensor)\n",
    "\n",
    "    return d2y_dx2\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Compute second derivative and convert result to NumPy\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "d2y_dx2 = fun_g2(x_tensor)\n",
    "\n",
    "# Convert tensor result to NumPy for printing / downstream use\n",
    "# Expected output (approximately): exp([3,4,6]) = [20.0855, 54.5982, 403.4288]\n",
    "d2y_dx2.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 20.0855,  54.5982, 403.4288])\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# PyTorch: Computing 1st and 2nd Derivatives (Autodiff)\n",
    "# ============================================================\n",
    "#\n",
    "# Goal:\n",
    "#   Compute d^2/dx^2 of y = exp(x)\n",
    "#   for x = [3, 4, 6]\n",
    "#\n",
    "# PyTorch concept:\n",
    "#   - Set requires_grad=True on tensors\n",
    "#   - Use torch.autograd.grad\n",
    "#   - Use create_graph=True to enable higher-order derivatives\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Create input tensor with gradient tracking enabled\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# requires_grad=True tells PyTorch:\n",
    "# \"Track operations on this tensor for automatic differentiation\"\n",
    "\n",
    "x = torch.tensor([3.0, 4.0, 6.0], requires_grad=True)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Define function and compute derivatives\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "def fun_g2(x):\n",
    "    \"\"\"\n",
    "    Computes second derivative of y = exp(x).\n",
    "\n",
    "    In PyTorch:\n",
    "    - First use autograd.grad to compute dy/dx\n",
    "    - Then differentiate dy/dx again\n",
    "    \"\"\"\n",
    "\n",
    "    # Forward computation\n",
    "    y = torch.exp(x)\n",
    "\n",
    "    # First derivative: dy/dx\n",
    "    # create_graph=True keeps the graph so we can differentiate again\n",
    "    dy_dx = torch.autograd.grad(\n",
    "        y, x,\n",
    "        grad_outputs=torch.ones_like(y),\n",
    "        create_graph=True\n",
    "    )[0]\n",
    "\n",
    "    # Second derivative: d2y/dx2\n",
    "    d2y_dx2 = torch.autograd.grad(\n",
    "        dy_dx, x,\n",
    "        grad_outputs=torch.ones_like(dy_dx)\n",
    "    )[0]\n",
    "\n",
    "    return d2y_dx2\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Compute second derivative\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "d2y_dx2 = fun_g2(x)\n",
    "\n",
    "print(d2y_dx2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
